{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WpFWrOSTIlCQ"
      },
      "source": [
        "# **Code for Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "f_bwgzHgo3JS"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # to load dataset\n",
        "import math\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim\n",
        "import os\n",
        "\n",
        "#%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHabcSsao2TJ",
        "outputId": "df23dc6b-4983-4a5a-df61-874d39e6dcaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device in use: cpu\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device in use: {device}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oc3Hvmoc5UR"
      },
      "source": [
        "## For Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo0OejbBc4VB",
        "outputId": "4e9594de-27af-4f51-8203-4afbdd44e439"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "# # linux command\n",
        "# %cd /content/drive/MyDrive/HapticData/"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QjkBExibcnm-"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lr1_F96LcnnB"
      },
      "outputs": [],
      "source": [
        "# define the dataset\n",
        "# 0 corresponds to rotating\n",
        "# 1 corresponds to grasping\n",
        "\n",
        "# num rows for one grasp (24 rows = 1 second)\n",
        "block_size = 24\n",
        "\n",
        "def normalize_vector(nd_arr: np.ndarray) -> np.ndarray:\n",
        "    vector_length = sum([i ** 2 for i in nd_arr]) ** 0.5\n",
        "    normalized_arr = [i / vector_length for i in nd_arr]\n",
        "    return normalized_arr\n",
        "\n",
        "# Rotation\n",
        "unedited_rotating_dataset = np.loadtxt('rotating.csv', delimiter=\",\")\n",
        "# Split into multiple movements over time (\"block_size\" seconds)\n",
        "edited_rotating_dataset = unedited_rotating_dataset[:,1:21] #corresponding to cols 2 - 21 inclusive, excluding the last row of zeros\n",
        "# edited_rotating_dataset = np.delete(edited_rotating_dataset, 5, 1)\n",
        "# Convert positions into velocities\n",
        "edited_rotating_dataset = np.diff(edited_rotating_dataset, axis=0)\n",
        "# Normalize each row\n",
        "edited_rotating_dataset = np.array([normalize_vector(row) for row in edited_rotating_dataset])\n",
        "\n",
        "# Grasping\n",
        "unedited_grasping_dataset = np.loadtxt('grasping.csv', delimiter=\",\")\n",
        "edited_grasping_dataset = unedited_grasping_dataset[:,1:21]\n",
        "# edited_grasping_dataset = np.delete(edited_grasping_dataset, 5, 1)\n",
        "edited_grasping_dataset = np.diff(edited_grasping_dataset, axis=0)\n",
        "# Normalize\n",
        "edited_grasping_dataset = np.array([normalize_vector(row) for row in edited_grasping_dataset])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kvHUpw2_cnnD"
      },
      "source": [
        "# Process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yPQUdDtEyXST"
      },
      "outputs": [],
      "source": [
        "columns = edited_rotating_dataset.shape[1]\n",
        "\n",
        "# Rotating\n",
        "rows = edited_rotating_dataset.shape[0]\n",
        "X = np.zeros((rows - block_size + 1, block_size * columns))  # number of rows times columns rows (from flattening)\n",
        "\n",
        "# For each block\n",
        "for i in range(0, rows - block_size + 1):\n",
        "  # Get entire row, 1st block_size * 24 rows, 2nd of them and so on..\n",
        "  X[i] = np.ndarray.flatten(edited_rotating_dataset[i : i + block_size, :])\n",
        "\n",
        "# X now contains mutliple blocks\n",
        "y = np.zeros((rows - block_size + 1))\n",
        "\n",
        "\n",
        "# grasping\n",
        "rows = edited_grasping_dataset.shape[0]\n",
        "X2 = np.zeros((rows - block_size + 1, block_size * columns))\n",
        "# For each block\n",
        "for i in range(0, rows - block_size + 1):\n",
        "  # Get entire row, 1st, block_size * 24 rows, second of them and so on..\n",
        "  X2[i] = np.ndarray.flatten(edited_grasping_dataset[i : i + block_size, :])\n",
        "# X now contains mutliple blocks\n",
        "y2 = np.ones((rows - block_size + 1))\n",
        "combined_X = np.concatenate((X, X2), axis=0)\n",
        "combined_y = np.concatenate((y, y2), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE5vNFavWF2j",
        "outputId": "2430e405-ff92-4fc2-914d-590e6ba381d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "columns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5TN1FrlfC_35"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qElWVb5fC_36"
      },
      "outputs": [],
      "source": [
        "# column_names = [i + 1 for i in range(20)]\n",
        "# graph_combined_X = pd.DataFrame(combined_X)\n",
        "# graph_combined_X['labels'] = combined_y\n",
        "# sns.pairplot(graph_combined_X, vars=column_names, hue=\"labels\")\n",
        "\n",
        "# # remove these columns\n",
        "# highly_correlated_cols = [] # put column numbers here\n",
        "# combined_X = np.delete(combined_X, highly_correlated_cols, axis=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TeWk_1YCcnnF"
      },
      "source": [
        "## Prepare for Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0SU43jpH6Vt",
        "outputId": "51b7d7ff-d8db-422b-f579-3eebbefb495d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total data size: 3430\n",
            "Train data size: 2401\n",
            "Test data size:  1029\n"
          ]
        }
      ],
      "source": [
        "# Split training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_X, combined_y, test_size=0.3, random_state=42)\n",
        "\n",
        "# covnert into tensors since numpy uses 64 bit floating point\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "y_train = torch.reshape(y_train,(-1,1)) # a single dimension uses -1 to infer the length. new shape\n",
        "y_test = torch.reshape(y_test,(-1,1)) # a single dimension uses -1 to infer the length. new shape\n",
        "\n",
        "print(f\"Total data size: {combined_X.shape[0]}\")\n",
        "print(f\"Train data size: {X_train.shape[0]}\")\n",
        "print(f\"Test data size:  {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVsm3hfno_-i",
        "outputId": "ef0af2f2-3fe4-426e-8956-8f2e1493105d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input size 480\n"
          ]
        }
      ],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(block_size * columns, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "print(f\"input size {block_size * columns}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9v3oCcTp-0q",
        "outputId": "43407462-c704-4740-f2b0-902c28a59a93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "X_train.to(device)\n",
        "y_train.to(device)\n",
        "X_test.to(device)\n",
        "y_test.to(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8QKRiXTGL4wC"
      },
      "source": [
        "## Preparation for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Kpdsuy9KLsvl"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.BCELoss() # used for binary classification problems\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sDAutLercnnK"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQA9YX0nOpD0",
        "outputId": "6592b601-3c1e-49c0-b897-fc63e58b13ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU: Finished epoch 14, latest loss 2.3154441322171485e-21\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 15\n",
        "batch_size = 4\n",
        "\n",
        "# CPU\n",
        "if device == \"cpu\":\n",
        "  for epoch in range(n_epochs):\n",
        "    for i in range(0, len(X) - batch_size, batch_size):\n",
        "      Xbatch = X_train[i:i+batch_size] # specifying the rows\n",
        "      y_pred = model(Xbatch) # scalar\n",
        "      ybatch = y_train[i:i+batch_size]\n",
        "      loss = loss_fn(y_pred, ybatch)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print(f\"epoch: {epoch + 1}/{n_epochs}\", end=\"\\r\")\n",
        "  print(f'CPU: Finished epoch {epoch}, latest loss {loss}')\n",
        "\n",
        "# GPU\n",
        "elif device == \"cuda\":\n",
        "  for epoch in range(n_epochs):\n",
        "    for i in range(0, len(X) - batch_size, batch_size):\n",
        "      Xbatch = X_train[i:i+batch_size] # specifying the rows\n",
        "      y_pred = model(Xbatch.cuda()) # scalar\n",
        "      ybatch = y_train[i:i+batch_size].cuda()\n",
        "      loss = loss_fn(y_pred, ybatch)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print(f\"epoch: {epoch + 1}/{n_epochs}\", end=\"\\r\")\n",
        "    print(f'CUDA: Finished epoch {epoch}, latest loss {loss}')\n",
        "else:\n",
        "  print(\"Not using CPU or CUDA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEcBZ3U9aYrA",
        "outputId": "38527dd7-0b99-44c5-c40b-d5281dd3ea36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data Accuracy: 98.70887756347656%\n",
            "Testing Data Accuracy: 94.94654846191406%\n"
          ]
        }
      ],
      "source": [
        "# evaluate the accuracy of the model\n",
        "\n",
        "with torch.no_grad():  # no_grad to avoid differentiating\n",
        "    y_pred1 = model(X_train.to(device))\n",
        "    y_pred2 = model(X_test.to(device))\n",
        "\n",
        "\n",
        "# rounds prediction to nearest integer, check if equal to y\n",
        "accuracy1 = (y_pred1.round() == y_train.to(device)).float().mean()\n",
        "accuracy2 = (y_pred2.round() == y_test.to(device)).float().mean()\n",
        "print(f\"Training Data Accuracy: {accuracy1 * 100}%\")\n",
        "print(f\"Testing Data Accuracy: {accuracy2 * 100}%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jMn6hrMGDuff"
      },
      "source": [
        "###Save model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2V9VToLnDpKt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "linear_relu_stack.0.weight \t torch.Size([256, 480])\n",
            "linear_relu_stack.0.bias \t torch.Size([256])\n",
            "linear_relu_stack.2.weight \t torch.Size([128, 256])\n",
            "linear_relu_stack.2.bias \t torch.Size([128])\n",
            "linear_relu_stack.4.weight \t torch.Size([64, 128])\n",
            "linear_relu_stack.4.bias \t torch.Size([64])\n",
            "linear_relu_stack.6.weight \t torch.Size([1, 64])\n",
            "linear_relu_stack.6.bias \t torch.Size([1])\n",
            "state \t {0: {'step': tensor(6915.), 'exp_avg': tensor([[ 8.9980e-11, -1.4563e-08, -3.7514e-09,  ...,  4.3938e-09,\n",
            "          1.2765e-08,  2.0681e-08],\n",
            "        [-3.9767e-08, -1.9852e-08, -6.9690e-08,  ...,  6.2616e-09,\n",
            "          5.9518e-09,  7.5887e-08],\n",
            "        [ 1.7139e-07,  5.8344e-08,  2.1700e-07,  ..., -2.0211e-07,\n",
            "          1.7526e-08, -1.7581e-07],\n",
            "        ...,\n",
            "        [ 7.5802e-09, -5.0852e-08,  6.3128e-07,  ...,  1.0602e-07,\n",
            "          5.0073e-08, -7.9404e-08],\n",
            "        [ 1.6447e-10, -3.4353e-09,  2.5596e-07,  ..., -1.6516e-07,\n",
            "         -2.1539e-08, -7.0915e-08],\n",
            "        [-2.4766e-11, -2.3616e-09,  9.3062e-10,  ...,  6.0547e-09,\n",
            "         -1.3717e-08,  4.3883e-08]]), 'exp_avg_sq': tensor([[1.0874e-07, 1.8398e-07, 5.8958e-08,  ..., 1.3958e-07, 1.8214e-07,\n",
            "         1.6153e-07],\n",
            "        [8.8548e-08, 1.4506e-07, 1.1089e-07,  ..., 7.0900e-08, 1.5267e-07,\n",
            "         2.9301e-07],\n",
            "        [1.7169e-07, 2.5767e-07, 2.0228e-07,  ..., 2.3686e-07, 1.7567e-07,\n",
            "         5.0242e-07],\n",
            "        ...,\n",
            "        [2.4769e-07, 6.2736e-07, 2.5018e-07,  ..., 4.2975e-07, 4.3477e-07,\n",
            "         1.7450e-06],\n",
            "        [9.3903e-09, 2.7155e-08, 1.5561e-08,  ..., 3.7128e-08, 4.1683e-08,\n",
            "         5.0757e-08],\n",
            "        [3.9690e-08, 1.4624e-07, 9.4123e-08,  ..., 1.1701e-07, 1.0634e-07,\n",
            "         2.4338e-07]])}, 1: {'step': tensor(6915.), 'exp_avg': tensor([-1.0002e-07,  6.1183e-07, -2.1027e-06, -1.5155e-06, -1.8620e-06,\n",
            "         2.8403e-07,  6.7467e-07, -8.6882e-07, -8.9671e-07, -1.3351e-07,\n",
            "        -1.0157e-06,  2.7899e-07,  2.4093e-07, -4.1893e-07,  6.5290e-07,\n",
            "         1.0988e-06, -2.8485e-06,  2.8466e-07, -3.2952e-06, -1.0461e-06,\n",
            "        -1.1425e-06, -2.1514e-06, -2.3220e-06,  6.5265e-07, -3.2234e-06,\n",
            "         2.1672e-07,  1.2044e-06,  4.5083e-07,  2.0622e-06, -1.2385e-06,\n",
            "        -7.7902e-07, -4.1871e-07,  2.1960e-07,  5.7010e-08, -3.9951e-06,\n",
            "        -2.4226e-06, -5.6792e-07,  2.2652e-06, -4.6048e-06,  2.3190e-08,\n",
            "        -4.2062e-06,  6.5999e-07, -1.4843e-06, -8.8831e-07, -4.0994e-06,\n",
            "        -4.2520e-07, -1.0088e-06, -9.0843e-07,  2.4883e-06, -3.0851e-07,\n",
            "        -5.7108e-07,  3.0020e-08,  4.5067e-07, -7.1034e-07, -4.2277e-07,\n",
            "         1.4088e-07,  1.7831e-07,  2.8553e-06,  7.7932e-07, -7.0924e-07,\n",
            "        -4.2632e-06, -1.3717e-06,  1.3192e-07, -2.7564e-07,  5.1644e-08,\n",
            "        -1.4451e-07,  2.6082e-06, -1.1451e-06, -1.5090e-06,  4.1286e-07,\n",
            "         9.2599e-07, -3.1479e-06, -1.2164e-06,  6.2565e-07, -7.3157e-07,\n",
            "         2.3318e-07, -4.2335e-08, -3.1293e-07, -6.4415e-08,  5.0942e-07,\n",
            "         1.4638e-06, -1.5538e-06, -1.3184e-09, -8.0222e-07, -4.1055e-06,\n",
            "        -4.1453e-06, -8.4215e-07,  2.0482e-06, -2.7843e-06, -1.0337e-07,\n",
            "        -1.0689e-06, -3.4748e-08,  3.6033e-07, -2.6805e-07,  4.8779e-07,\n",
            "         5.1174e-07, -1.4852e-07, -2.6500e-06, -1.5500e-06,  4.0773e-07,\n",
            "        -2.5926e-06,  6.6233e-07, -7.9845e-07,  3.3172e-06,  3.9925e-07,\n",
            "         7.0859e-09,  4.7590e-07, -7.2046e-07, -1.1420e-06, -9.2189e-07,\n",
            "         1.2691e-07,  4.9107e-07, -3.3454e-06, -1.9167e-07,  1.4310e-06,\n",
            "        -1.9628e-07,  4.6117e-07, -2.1422e-08,  8.0268e-07, -1.9645e-07,\n",
            "        -1.4958e-06,  7.6813e-07, -2.9814e-06, -1.1115e-07, -1.6636e-06,\n",
            "         2.0803e-06, -2.6096e-07, -3.6760e-06,  4.1756e-07, -2.0052e-06,\n",
            "        -9.5970e-07, -8.5169e-07, -3.2458e-07, -3.8427e-07, -1.7460e-07,\n",
            "         3.3110e-07, -4.8966e-07,  9.5727e-07, -5.9707e-08, -7.0828e-07,\n",
            "        -3.0499e-08, -4.1276e-07, -1.5398e-06, -1.8769e-06, -6.0846e-07,\n",
            "        -2.4834e-07, -9.3969e-07, -9.1688e-07,  1.0216e-06, -2.3291e-06,\n",
            "         2.5388e-06, -2.7983e-07, -5.8244e-07,  1.1314e-07,  2.1487e-07,\n",
            "        -2.5040e-06, -4.0080e-07,  4.9055e-07, -3.6132e-07,  2.9258e-06,\n",
            "         2.2576e-06, -2.2074e-07, -1.4219e-07, -3.0970e-06, -9.1464e-07,\n",
            "         1.4254e-07, -6.3885e-07, -3.7461e-07, -1.6257e-06, -1.5108e-06,\n",
            "        -6.8771e-07,  1.7945e-06,  4.4350e-07,  8.7416e-08, -1.3681e-06,\n",
            "        -1.8031e-06,  2.5104e-07, -2.5253e-06,  3.3638e-07, -1.1009e-06,\n",
            "        -1.0033e-06, -1.8186e-07, -2.9517e-07,  8.1979e-07,  1.1355e-06,\n",
            "        -3.5120e-06, -3.6290e-06,  1.1446e-08, -7.5249e-07, -2.1647e-06,\n",
            "         3.5622e-06, -5.1963e-07,  4.0888e-07,  2.8428e-07, -1.8088e-07,\n",
            "        -2.5176e-06, -1.6284e-06, -1.7895e-06,  2.0487e-07,  5.1192e-07,\n",
            "         3.6762e-07,  8.9935e-07,  5.4339e-07,  3.7392e-07, -1.5065e-06,\n",
            "        -1.6922e-06, -4.4331e-08,  3.2350e-07, -1.9510e-06,  3.4898e-07,\n",
            "        -2.1173e-07,  1.0774e-06,  4.4531e-07, -1.8733e-06, -3.0523e-07,\n",
            "        -4.2697e-07,  4.6288e-07, -6.7869e-07, -1.5495e-06,  1.7072e-07,\n",
            "         2.0879e-08, -3.7612e-07, -3.3691e-06,  6.9458e-07, -2.9198e-06,\n",
            "        -1.5044e-06, -2.7670e-06, -7.2454e-07, -7.3428e-07, -1.5121e-06,\n",
            "        -1.0864e-06, -1.0869e-06,  2.4577e-08, -2.7068e-06, -6.1688e-07,\n",
            "         9.3723e-08, -9.5251e-07, -2.0603e-06, -7.3025e-07,  1.9251e-06,\n",
            "         1.4586e-07, -7.3691e-07, -6.3139e-07, -1.5840e-07,  1.3244e-06,\n",
            "        -4.5435e-07, -3.7544e-07, -1.0924e-06,  5.5685e-07, -1.4352e-06,\n",
            "        -3.3516e-06, -2.3976e-06, -5.3633e-07, -3.3945e-06, -2.1922e-06,\n",
            "         8.8598e-08]), 'exp_avg_sq': tensor([2.1593e-06, 2.1924e-06, 6.2926e-06, 5.7091e-06, 8.4972e-06, 3.2983e-06,\n",
            "        4.6934e-06, 6.4544e-06, 5.2801e-07, 9.9144e-07, 1.1147e-06, 5.1585e-06,\n",
            "        7.1532e-07, 8.2487e-07, 1.9126e-06, 5.8786e-06, 1.0229e-05, 4.6213e-06,\n",
            "        5.3718e-06, 5.6124e-06, 2.6586e-06, 4.0977e-06, 2.4426e-06, 7.7313e-06,\n",
            "        5.0551e-07, 5.4411e-06, 6.0946e-06, 1.2195e-06, 5.7391e-06, 4.3209e-07,\n",
            "        7.0951e-07, 1.2349e-06, 2.5829e-06, 2.9700e-06, 3.3436e-06, 5.2962e-06,\n",
            "        2.8249e-06, 3.5107e-06, 1.9568e-06, 1.6219e-06, 7.7041e-06, 2.3750e-06,\n",
            "        8.2071e-07, 2.1787e-06, 1.3198e-06, 1.7934e-06, 4.4769e-07, 2.5802e-07,\n",
            "        5.5995e-06, 1.9934e-06, 6.1684e-07, 1.8473e-06, 1.3661e-06, 2.2384e-06,\n",
            "        2.1702e-06, 2.8420e-06, 2.1300e-06, 1.1502e-05, 8.7609e-06, 5.6022e-06,\n",
            "        1.2348e-05, 4.4133e-06, 2.3906e-06, 1.8426e-06, 5.5071e-07, 2.0314e-06,\n",
            "        9.4252e-06, 7.9171e-06, 3.3767e-06, 6.1976e-06, 5.2299e-06, 3.7266e-06,\n",
            "        1.3268e-06, 1.0582e-05, 3.7752e-06, 6.1446e-06, 1.1937e-06, 3.5604e-07,\n",
            "        1.5828e-06, 3.0845e-06, 7.9712e-06, 1.7437e-06, 7.9274e-07, 6.1143e-06,\n",
            "        4.3400e-06, 6.9756e-06, 2.1690e-06, 7.0201e-06, 5.1691e-06, 1.2676e-06,\n",
            "        2.4725e-06, 4.7664e-07, 3.3737e-06, 2.2384e-06, 3.5310e-06, 2.2324e-06,\n",
            "        1.0002e-06, 5.6526e-06, 7.3062e-06, 3.3306e-06, 5.6702e-06, 5.8620e-06,\n",
            "        5.2023e-06, 1.0639e-05, 1.6813e-05, 7.3884e-07, 1.1191e-05, 1.6065e-06,\n",
            "        2.0018e-06, 2.7417e-06, 7.9446e-07, 6.3613e-06, 2.4945e-06, 8.0800e-07,\n",
            "        1.0636e-05, 7.4285e-07, 1.0672e-05, 1.1940e-06, 1.6129e-05, 1.9889e-06,\n",
            "        1.3344e-06, 4.8809e-06, 1.6135e-06, 7.4134e-07, 1.8691e-06, 1.3658e-05,\n",
            "        2.9693e-06, 6.2091e-06, 2.6702e-06, 5.0014e-06, 1.6667e-06, 1.0369e-05,\n",
            "        6.5771e-06, 3.3049e-06, 9.1982e-07, 6.7823e-06, 1.8667e-06, 7.8679e-06,\n",
            "        5.0021e-07, 9.7083e-07, 1.8232e-06, 2.2367e-06, 1.5212e-06, 3.4162e-06,\n",
            "        1.2659e-06, 1.0444e-06, 1.0806e-06, 3.7663e-07, 4.8594e-06, 9.5238e-06,\n",
            "        4.8835e-06, 5.2360e-07, 1.6795e-06, 4.0999e-06, 3.2277e-07, 1.9476e-06,\n",
            "        9.1590e-07, 1.0700e-06, 9.9950e-07, 9.3496e-06, 4.6473e-06, 6.6704e-07,\n",
            "        2.2710e-06, 6.2646e-06, 7.4568e-07, 2.2703e-06, 6.9882e-07, 1.5544e-06,\n",
            "        5.9637e-06, 7.8096e-06, 4.5379e-06, 2.4347e-05, 8.7714e-06, 7.3426e-06,\n",
            "        5.8540e-07, 2.7838e-06, 4.9416e-06, 7.0968e-07, 8.7969e-06, 8.2354e-07,\n",
            "        1.4127e-06, 2.7537e-06, 2.7081e-06, 2.8537e-06, 6.5457e-06, 4.9996e-06,\n",
            "        2.3324e-06, 6.3080e-07, 1.5920e-06, 2.7717e-06, 1.0979e-05, 3.2493e-06,\n",
            "        1.1604e-05, 8.4662e-06, 8.0916e-07, 5.3223e-06, 4.3044e-06, 2.1770e-06,\n",
            "        1.9853e-06, 1.7753e-05, 3.3201e-06, 3.0508e-06, 2.3525e-06, 3.2648e-06,\n",
            "        1.6406e-06, 1.4603e-06, 8.6389e-07, 7.2560e-07, 1.6464e-06, 1.2665e-05,\n",
            "        3.0080e-06, 1.0933e-06, 2.2906e-06, 4.3077e-07, 1.1375e-06, 8.9331e-07,\n",
            "        1.0988e-06, 6.7674e-07, 1.3382e-05, 4.8133e-06, 2.4314e-07, 1.4390e-06,\n",
            "        8.3972e-06, 1.0083e-05, 3.3468e-06, 1.1005e-06, 4.9570e-06, 3.2582e-07,\n",
            "        1.5471e-06, 1.0816e-06, 1.0137e-06, 2.5812e-06, 2.4764e-06, 4.3591e-06,\n",
            "        1.0804e-06, 7.1014e-07, 1.2245e-06, 1.4173e-06, 8.7931e-06, 7.9066e-06,\n",
            "        2.1007e-06, 3.6182e-06, 3.7662e-06, 1.4880e-07, 3.7535e-06, 9.3308e-07,\n",
            "        1.7857e-06, 2.8102e-06, 2.0846e-06, 5.7127e-06, 3.6932e-06, 9.6602e-06,\n",
            "        5.0664e-06, 7.7696e-06, 7.4573e-07, 4.2787e-06])}, 2: {'step': tensor(6915.), 'exp_avg': tensor([[-8.7081e-08, -2.4368e-07, -1.1663e-07,  ..., -1.1666e-07,\n",
            "         -4.5252e-07, -7.2883e-09],\n",
            "        [-1.1614e-07, -3.4011e-07, -1.6272e-07,  ..., -1.7207e-07,\n",
            "         -6.5969e-07, -1.0224e-08],\n",
            "        [-2.5694e-11, -7.7469e-09, -3.6212e-09,  ..., -6.2225e-13,\n",
            "          1.4021e-09, -7.5479e-13],\n",
            "        ...,\n",
            "        [ 1.3578e-07,  5.2503e-08,  4.0132e-08,  ...,  9.7608e-10,\n",
            "          3.7401e-08,  1.9327e-08],\n",
            "        [ 1.7064e-09, -3.6592e-09, -1.7301e-09,  ...,  5.6496e-09,\n",
            "          8.4705e-10, -4.2957e-13],\n",
            "        [-1.3030e-07, -3.4593e-07, -1.6796e-07,  ..., -1.7063e-07,\n",
            "         -6.7216e-07, -1.0322e-08]]), 'exp_avg_sq': tensor([[6.5375e-08, 1.0017e-07, 7.9422e-08,  ..., 9.3262e-08, 1.1213e-08,\n",
            "         6.2700e-08],\n",
            "        [9.0647e-08, 2.1629e-07, 1.0425e-07,  ..., 8.9289e-08, 2.6493e-08,\n",
            "         4.1916e-08],\n",
            "        [1.5528e-07, 1.2330e-06, 3.6363e-07,  ..., 4.2216e-07, 3.0842e-08,\n",
            "         6.6145e-08],\n",
            "        ...,\n",
            "        [7.1781e-07, 1.1337e-07, 5.5655e-07,  ..., 6.1967e-07, 1.5914e-07,\n",
            "         3.5931e-07],\n",
            "        [2.9502e-08, 3.3355e-07, 8.7954e-08,  ..., 3.2744e-07, 6.1290e-09,\n",
            "         1.3559e-08],\n",
            "        [1.1647e-07, 2.6608e-07, 1.3627e-07,  ..., 1.4094e-07, 3.7189e-08,\n",
            "         5.6181e-08]])}, 3: {'step': tensor(6915.), 'exp_avg': tensor([-1.2583e-06, -1.7983e-06, -1.4812e-08, -2.2075e-06,  5.6052e-45,\n",
            "         1.5324e-07, -2.4134e-07, -1.7664e-06,  8.9995e-08, -1.8067e-06,\n",
            "         9.0938e-07, -2.8242e-06, -1.5974e-06, -2.8824e-08,  1.7844e-07,\n",
            "        -1.1557e-06, -2.3528e-08, -2.5166e-06, -1.9706e-09,  9.7325e-08,\n",
            "        -1.5237e-06, -1.6891e-08, -2.1039e-06, -2.9307e-08, -9.1932e-08,\n",
            "        -2.6443e-06, -1.2485e-08, -2.0306e-06,  4.1033e-09, -2.0361e-06,\n",
            "        -3.6944e-07, -3.0687e-08, -1.5903e-06,  3.0585e-14, -2.3225e-06,\n",
            "        -2.0603e-08, -5.0510e-15, -1.6705e-06, -2.1479e-06, -3.5328e-08,\n",
            "        -1.4767e-06, -3.8153e-08,  3.1130e-08,  1.4705e-07,  1.0573e-07,\n",
            "         5.6052e-45,  3.2078e-08, -5.2941e-14, -2.9672e-07, -1.2291e-06,\n",
            "        -1.1993e-08,  1.1469e-07,  1.5941e-07, -4.2866e-08,  1.6213e-07,\n",
            "        -4.3407e-09, -2.1084e-08, -2.4020e-08, -1.3384e-06,  2.6403e-07,\n",
            "        -1.0171e-06, -1.5135e-06, -1.1096e-06, -3.6071e-09, -2.1091e-06,\n",
            "         1.3337e-08, -1.5068e-06, -1.6454e-06, -7.7098e-07, -1.9325e-06,\n",
            "        -2.6485e-08,  2.0169e-07,  1.3112e-07,  1.0430e-07,  5.6052e-45,\n",
            "        -1.3597e-06, -2.3922e-06, -2.3076e-08,  1.1648e-07,  5.6052e-45,\n",
            "        -3.3162e-08, -2.4914e-08, -1.8574e-06, -2.2047e-08, -8.9470e-09,\n",
            "        -5.6052e-45, -8.6054e-22, -1.4975e-06, -2.3082e-08, -2.0516e-06,\n",
            "         1.4734e-07, -1.4625e-06, -3.3059e-08,  5.6052e-45, -3.8859e-08,\n",
            "        -3.0275e-06,  1.5294e-07, -2.9077e-08, -5.1022e-22,  6.0725e-08,\n",
            "        -2.0759e-06, -8.6110e-09,  4.4731e-07,  1.2839e-07, -1.6967e-09,\n",
            "        -1.8836e-06,  1.6667e-07, -1.4999e-08,  5.6052e-45, -3.0440e-08,\n",
            "        -3.0901e-06, -1.4905e-32, -5.8319e-09, -1.6342e-06, -2.6003e-08,\n",
            "         5.6052e-45, -1.3129e-06,  3.1471e-07, -1.9761e-06,  2.7832e-07,\n",
            "        -7.5427e-09, -5.0700e-09, -4.2055e-08,  1.0330e-07,  1.9953e-07,\n",
            "         1.7400e-07,  4.1191e-09, -1.8374e-06]), 'exp_avg_sq': tensor([3.5849e-07, 7.0959e-07, 2.1138e-06, 1.6332e-06, 2.8847e-11, 5.7463e-07,\n",
            "        2.5860e-08, 1.8486e-06, 1.1583e-06, 1.3463e-06, 4.6540e-06, 2.3896e-06,\n",
            "        3.6241e-07, 1.6951e-06, 1.5994e-06, 7.0164e-07, 1.7917e-08, 2.1833e-06,\n",
            "        8.8772e-07, 8.6645e-07, 1.3722e-06, 5.0037e-07, 1.4195e-06, 8.7178e-07,\n",
            "        1.6410e-07, 1.2553e-06, 1.0948e-06, 1.5415e-06, 1.7529e-06, 8.1517e-07,\n",
            "        7.0921e-08, 1.1434e-06, 9.2949e-07, 7.5568e-09, 2.0387e-06, 8.7617e-07,\n",
            "        1.0250e-07, 1.3807e-06, 1.0354e-06, 2.4637e-06, 1.1081e-06, 1.2462e-06,\n",
            "        2.5300e-06, 1.4474e-06, 1.2042e-06, 1.2177e-11, 2.8008e-06, 8.0381e-09,\n",
            "        6.8402e-09, 3.2026e-08, 2.4031e-06, 1.1908e-06, 6.1868e-07, 2.4816e-07,\n",
            "        4.1888e-07, 5.4434e-07, 6.9106e-08, 1.3869e-06, 2.0254e-07, 1.0286e-06,\n",
            "        1.1812e-07, 5.6255e-07, 7.8423e-07, 9.9806e-08, 1.0671e-06, 3.9610e-07,\n",
            "        3.1942e-07, 1.8709e-07, 4.2415e-07, 1.8232e-06, 1.9578e-07, 3.8043e-07,\n",
            "        1.1814e-06, 6.5866e-07, 3.7965e-10, 5.6953e-07, 3.8347e-06, 4.0710e-07,\n",
            "        2.3964e-06, 8.9068e-11, 1.1825e-07, 5.2656e-07, 2.4628e-06, 7.6427e-09,\n",
            "        1.3473e-06, 1.9693e-11, 1.0692e-07, 3.8073e-07, 1.0981e-06, 1.0298e-06,\n",
            "        8.3027e-07, 9.4361e-07, 1.4894e-06, 1.1207e-07, 2.0435e-06, 7.9673e-07,\n",
            "        1.1780e-06, 1.4327e-06, 5.9675e-08, 6.8705e-07, 2.5114e-06, 2.6708e-06,\n",
            "        2.5646e-06, 6.8132e-07, 1.7941e-06, 2.2490e-07, 1.6454e-06, 3.7331e-06,\n",
            "        5.3404e-14, 1.1192e-06, 8.8475e-07, 3.5161e-10, 5.5193e-08, 1.3733e-07,\n",
            "        5.3958e-07, 2.2137e-11, 6.1708e-07, 9.9401e-07, 8.7629e-07, 7.6410e-07,\n",
            "        1.1657e-07, 3.0411e-08, 2.7571e-06, 5.8495e-07, 1.7834e-06, 2.5327e-06,\n",
            "        8.1621e-07, 8.8945e-07])}, 4: {'step': tensor(6915.), 'exp_avg': tensor([[-7.0843e-12, -1.1624e-13, -2.1811e-12,  ..., -2.4480e-11,\n",
            "         -8.3682e-12, -5.8851e-20],\n",
            "        [-6.7566e-10, -2.4267e-11, -7.4010e-10,  ..., -2.0543e-09,\n",
            "         -1.2435e-09, -2.0947e-10],\n",
            "        [ 6.8610e-09,  6.3436e-09, -9.3929e-10,  ..., -6.0977e-10,\n",
            "         -1.5782e-09,  5.9086e-09],\n",
            "        ...,\n",
            "        [ 5.6052e-45,  0.0000e+00,  5.6052e-45,  ...,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [-4.2606e-07, -4.8981e-07, -2.9872e-11,  ..., -4.7030e-09,\n",
            "         -1.5843e-09, -3.8052e-07],\n",
            "        [ 4.4795e-08,  5.7003e-08, -8.0039e-10,  ...,  3.9549e-09,\n",
            "         -1.3448e-09,  5.3279e-08]]), 'exp_avg_sq': tensor([[4.6570e-11, 5.1774e-11, 3.0318e-11,  ..., 2.1125e-10, 4.1988e-11,\n",
            "         4.9001e-11],\n",
            "        [9.9383e-09, 3.4671e-08, 1.4610e-08,  ..., 2.6361e-08, 2.5754e-08,\n",
            "         2.7143e-08],\n",
            "        [1.1831e-07, 1.7102e-07, 3.4840e-08,  ..., 1.2528e-07, 8.1427e-08,\n",
            "         1.2344e-07],\n",
            "        ...,\n",
            "        [5.4480e-15, 0.0000e+00, 1.0084e-11,  ..., 4.0223e-19, 1.3546e-13,\n",
            "         1.3400e-13],\n",
            "        [4.2926e-08, 6.6331e-08, 1.3584e-08,  ..., 2.0482e-08, 2.2338e-08,\n",
            "         5.4630e-08],\n",
            "        [7.6321e-08, 1.0935e-07, 2.1175e-08,  ..., 7.7956e-08, 5.3603e-08,\n",
            "         7.8318e-08]])}, 5: {'step': tensor(6915.), 'exp_avg': tensor([-2.9071e-10, -9.9192e-09, -6.5661e-09, -4.5530e-09, -3.6959e-09,\n",
            "        -7.6555e-07, -1.0874e-06,  3.0089e-07, -9.9687e-07,  5.6052e-45,\n",
            "         0.0000e+00, -5.4086e-09,  2.8937e-08, -6.2669e-07,  1.7671e-07,\n",
            "        -1.3543e-06, -2.7292e-09, -7.9129e-09,  5.6052e-45,  5.3559e-08,\n",
            "        -4.5850e-07,  4.9416e-08, -1.1860e-08, -8.3232e-07, -9.2934e-09,\n",
            "        -7.9012e-07, -6.6947e-07, -6.5277e-07, -5.4366e-07, -1.4587e-06,\n",
            "         1.9193e-07, -1.2541e-08, -8.8932e-09,  5.6052e-45,  4.2656e-08,\n",
            "        -1.2014e-06, -7.9844e-07, -1.5827e-06, -2.7736e-07, -1.0079e-06,\n",
            "         6.6332e-08, -8.5670e-07, -1.2189e-06,  4.0219e-08, -1.3096e-06,\n",
            "         4.0386e-08,  7.1828e-08, -3.5949e-09, -5.2360e-07,  5.6052e-45,\n",
            "        -6.9711e-07,  9.5079e-08,  1.5634e-09, -1.6176e-08, -8.0255e-09,\n",
            "        -1.0721e-06, -1.5834e-08, -1.9144e-08, -1.1713e-06, -3.5867e-09,\n",
            "         1.0628e-07,  5.6052e-45, -5.6785e-07,  3.7763e-08]), 'exp_avg_sq': tensor([1.4500e-09, 1.3238e-07, 5.0034e-07, 4.8599e-08, 1.2567e-07, 2.6111e-07,\n",
            "        7.3114e-07, 4.5703e-07, 4.9976e-07, 4.3048e-10, 0.0000e+00, 3.2521e-07,\n",
            "        7.8511e-08, 1.9008e-07, 5.3751e-08, 9.9968e-07, 7.1087e-08, 1.6656e-07,\n",
            "        8.0028e-11, 6.9194e-07, 1.3713e-07, 5.2283e-07, 1.9816e-07, 3.5292e-07,\n",
            "        9.5023e-07, 3.4733e-07, 1.0447e-07, 2.1821e-07, 1.7522e-07, 1.3019e-06,\n",
            "        1.5457e-08, 4.1156e-07, 1.7559e-07, 2.6506e-10, 4.0913e-07, 8.5074e-07,\n",
            "        3.4263e-07, 1.4657e-07, 4.7767e-09, 6.5714e-07, 7.3718e-07, 3.2153e-07,\n",
            "        8.9784e-07, 3.1452e-07, 9.7886e-07, 2.8832e-07, 1.9729e-07, 2.7142e-08,\n",
            "        1.2082e-07, 1.1697e-10, 2.5661e-07, 3.9612e-07, 4.2891e-07, 1.2811e-08,\n",
            "        6.8640e-07, 6.8580e-07, 7.2706e-07, 1.0210e-06, 6.5676e-07, 3.9709e-08,\n",
            "        4.0212e-07, 1.4586e-10, 1.3206e-07, 3.0338e-07])}, 6: {'step': tensor(6915.), 'exp_avg': tensor([[ 1.0892e-09,  1.8913e-07,  2.2743e-07,  2.5681e-07,  2.8086e-07,\n",
            "         -1.5664e-05, -2.1804e-05,  4.4989e-08, -1.5665e-05,  5.6052e-45,\n",
            "          0.0000e+00,  1.9429e-07,  2.4034e-07, -1.6230e-05,  1.4418e-07,\n",
            "         -2.0943e-05,  2.4328e-07,  2.2640e-07,  5.6052e-45,  2.5636e-07,\n",
            "         -1.1416e-05,  2.1015e-07,  2.3206e-07, -1.5875e-05,  3.0620e-07,\n",
            "         -2.0481e-05, -1.1667e-05, -1.8034e-05, -1.6688e-05, -2.0751e-05,\n",
            "          5.6229e-07,  2.7727e-07,  2.8884e-07, -5.6052e-45,  2.1344e-07,\n",
            "         -2.2754e-05, -2.0455e-05, -4.5034e-05, -1.7766e-05, -1.4791e-05,\n",
            "         -5.6055e-09, -1.5188e-05, -2.0330e-05,  1.1724e-07, -2.1709e-05,\n",
            "          2.8040e-07,  2.0141e-07,  3.3375e-07, -2.1756e-05, -5.6052e-45,\n",
            "         -1.8494e-05,  1.4911e-07,  1.5734e-07,  6.0507e-07,  2.9201e-07,\n",
            "         -1.9983e-05,  2.0757e-07,  2.7253e-07, -1.6087e-05,  1.5190e-07,\n",
            "          1.4627e-07,  5.6052e-45, -1.5590e-05,  2.2218e-07]]), 'exp_avg_sq': tensor([[4.3173e-07, 2.9147e-06, 3.4948e-05, 2.6936e-05, 3.1926e-05, 2.7990e-05,\n",
            "         8.7417e-05, 2.5500e-05, 5.2556e-05, 7.6819e-12, 0.0000e+00, 3.5697e-05,\n",
            "         2.1767e-05, 4.2709e-05, 1.2880e-05, 6.8875e-05, 2.9213e-05, 2.9571e-05,\n",
            "         6.9275e-13, 4.8648e-05, 1.7572e-05, 3.0766e-05, 1.1002e-05, 3.9952e-05,\n",
            "         5.5584e-05, 7.6887e-05, 7.5072e-06, 6.8449e-05, 4.6501e-05, 1.0867e-04,\n",
            "         5.2629e-08, 4.6464e-05, 2.7085e-05, 4.1086e-10, 3.8971e-05, 1.0157e-04,\n",
            "         8.9375e-05, 3.6299e-05, 1.4855e-05, 5.5934e-05, 3.6331e-05, 2.7071e-05,\n",
            "         9.3385e-05, 1.8913e-05, 7.5866e-05, 4.5944e-05, 3.1507e-05, 1.0452e-05,\n",
            "         1.1607e-04, 1.0192e-11, 5.7009e-05, 4.3149e-05, 1.6833e-05, 1.2782e-06,\n",
            "         5.3183e-05, 7.5556e-05, 2.8807e-05, 5.2592e-05, 2.7372e-05, 1.4169e-05,\n",
            "         4.3972e-05, 4.7531e-10, 3.4843e-05, 4.8012e-05]])}, 7: {'step': tensor(6915.), 'exp_avg': tensor([-6.9383e-06]), 'exp_avg_sq': tensor([4.0292e-05])}}\n",
            "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n"
          ]
        }
      ],
      "source": [
        "# print state dict, a dictionary containing label for each weight/bias and their value\n",
        "for param_tensor in model.state_dict():\n",
        "  print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# print state dict for the optimizer, containing hyperparameters\n",
        "for var_name in optimizer.state_dict():\n",
        "  print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "K77pg7VJEXre"
      },
      "outputs": [],
      "source": [
        "# in google drive, this saves inside the folder that the notebook was initially mounted\n",
        "PATH = \"classifier.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Z8F_Woj_EoEO"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iz2EPzv5JKGu"
      },
      "source": [
        "# **Code for testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "99blsReqJJp5"
      },
      "outputs": [],
      "source": [
        "# replace variable with local path in linux\n",
        "PATH = \"classifier.pt\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nYGb80oUE5Px"
      },
      "source": [
        "### Load Existing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY_g84jpE0zW",
        "outputId": "b69c099f-8531-48db-9ce1-41da061430e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=480, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
              "    (7): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval() # must set dropout and batch normalization layers to evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qfIuH5oeJVRQ"
      },
      "outputs": [],
      "source": [
        "# import rospy\n",
        "# from std_msgs.msg import String\n",
        "\n",
        "# def callback(data):\n",
        "#     rospy.loginfo(rospy.get_caller_id() + 'I heard %s', data.data)\n",
        "\n",
        "# def listener():\n",
        "\n",
        "#     # In ROS, nodes are uniquely named. If two nodes with the same\n",
        "#     # name are launched, the previous one is kicked off. The\n",
        "#     # anonymous=True flag means that rospy will choose a unique\n",
        "#     # name for our 'listener' node so that multiple listeners can\n",
        "#     # run simultaneously.\n",
        "#     rospy.init_node('listener', anonymous=True)\n",
        "\n",
        "#     rospy.Subscriber('/senseglove/0/rh/joint_states', String, callback) # subscribes to this senseglove joints topic\n",
        "\n",
        "#     # spin() simply keeps python from exiting until this node is stopped\n",
        "#     rospy.spin()\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     listener()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
