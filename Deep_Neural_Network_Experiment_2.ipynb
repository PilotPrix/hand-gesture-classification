{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Code for Training**"
      ],
      "metadata": {
        "id": "WpFWrOSTIlCQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_bwgzHgo3JS"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # to load dataset\n",
        "import math\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim\n",
        "import os\n",
        "\n",
        "#%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHabcSsao2TJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df23dc6b-4983-4a5a-df61-874d39e6dcaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device in use: cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device in use: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oc3Hvmoc5UR"
      },
      "source": [
        "## For Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wo0OejbBc4VB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e9594de-27af-4f51-8203-4afbdd44e439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/HapticData\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "# linux command\n",
        "%cd /content/drive/MyDrive/HapticData/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjkBExibcnm-"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr1_F96LcnnB"
      },
      "outputs": [],
      "source": [
        "# define the dataset\n",
        "# 0 corresponds to rotating\n",
        "# 1 corresponds to grasping\n",
        "\n",
        "# num rows for one grasp (24 rows = 1 second)\n",
        "block_size = 24\n",
        "\n",
        "def normalize_vector(nd_arr: np.ndarray) -> np.ndarray:\n",
        "    vector_length = sum([i ** 2 for i in nd_arr]) ** 0.5\n",
        "    normalized_arr = [i / vector_length for i in nd_arr]\n",
        "    return normalized_arr\n",
        "\n",
        "# Rotation\n",
        "unedited_rotating_dataset = np.loadtxt('rotating.csv', delimiter=\",\")\n",
        "# Split into multiple movements over time (\"block_size\" seconds)\n",
        "edited_rotating_dataset = unedited_rotating_dataset[:,1:21] #corresponding to cols 2 - 21 inclusive, excluding the last row of zeros\n",
        "# edited_rotating_dataset = np.delete(edited_rotating_dataset, 5, 1)\n",
        "# Convert positions into velocities\n",
        "edited_rotating_dataset = np.diff(edited_rotating_dataset, axis=0)\n",
        "# Normalize each row\n",
        "edited_rotating_dataset = np.array([normalize_vector(row) for row in edited_rotating_dataset])\n",
        "\n",
        "# Grasping\n",
        "unedited_grasping_dataset = np.loadtxt('grasping.csv', delimiter=\",\")\n",
        "edited_grasping_dataset = unedited_grasping_dataset[:,1:21]\n",
        "# edited_grasping_dataset = np.delete(edited_grasping_dataset, 5, 1)\n",
        "edited_grasping_dataset = np.diff(edited_grasping_dataset, axis=0)\n",
        "# Normalize\n",
        "edited_grasping_dataset = np.array([normalize_vector(row) for row in edited_grasping_dataset])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvHUpw2_cnnD"
      },
      "source": [
        "# Process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPQUdDtEyXST"
      },
      "outputs": [],
      "source": [
        "columns = edited_rotating_dataset.shape[1]\n",
        "\n",
        "# Rotating\n",
        "rows = edited_rotating_dataset.shape[0]\n",
        "X = np.zeros((rows - block_size + 1, block_size * columns))  # number of rows times columns rows (from flattening)\n",
        "\n",
        "# For each block\n",
        "for i in range(0, rows - block_size + 1):\n",
        "  # Get entire row, 1st block_size * 24 rows, 2nd of them and so on..\n",
        "  X[i] = np.ndarray.flatten(edited_rotating_dataset[i : i + block_size, :])\n",
        "\n",
        "# X now contains mutliple blocks\n",
        "y = np.zeros((rows - block_size + 1))\n",
        "\n",
        "\n",
        "# grasping\n",
        "rows = edited_grasping_dataset.shape[0]\n",
        "X2 = np.zeros((rows - block_size + 1, block_size * columns))\n",
        "# For each block\n",
        "for i in range(0, rows - block_size + 1):\n",
        "  # Get entire row, 1st, block_size * 24 rows, second of them and so on..\n",
        "  X2[i] = np.ndarray.flatten(edited_grasping_dataset[i : i + block_size, :])\n",
        "# X now contains mutliple blocks\n",
        "y2 = np.ones((rows - block_size + 1))\n",
        "combined_X = np.concatenate((X, X2), axis=0)\n",
        "combined_y = np.concatenate((y, y2), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE5vNFavWF2j",
        "outputId": "2430e405-ff92-4fc2-914d-590e6ba381d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TN1FrlfC_35"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qElWVb5fC_36"
      },
      "outputs": [],
      "source": [
        "# column_names = [i + 1 for i in range(20)]\n",
        "# graph_combined_X = pd.DataFrame(combined_X)\n",
        "# graph_combined_X['labels'] = combined_y\n",
        "# sns.pairplot(graph_combined_X, vars=column_names, hue=\"labels\")\n",
        "\n",
        "# # remove these columns\n",
        "# highly_correlated_cols = [] # put column numbers here\n",
        "# combined_X = np.delete(combined_X, highly_correlated_cols, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeWk_1YCcnnF"
      },
      "source": [
        "## Prepare for Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0SU43jpH6Vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b7d7ff-d8db-422b-f579-3eebbefb495d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data size: 3432\n",
            "Train data size: 2402\n",
            "Test data size:  1030\n"
          ]
        }
      ],
      "source": [
        "# Split training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_X, combined_y, test_size=0.3, random_state=42)\n",
        "\n",
        "# covnert into tensors since numpy uses 64 bit floating point\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "y_train = torch.reshape(y_train,(-1,1)) # a single dimension uses -1 to infer the length. new shape\n",
        "y_test = torch.reshape(y_test,(-1,1)) # a single dimension uses -1 to infer the length. new shape\n",
        "\n",
        "print(f\"Total data size: {combined_X.shape[0]}\")\n",
        "print(f\"Train data size: {X_train.shape[0]}\")\n",
        "print(f\"Test data size:  {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVsm3hfno_-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0af2f2-3fe4-426e-8956-8f2e1493105d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input size 480\n"
          ]
        }
      ],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(block_size * columns, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "print(f\"input size {block_size * columns}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9v3oCcTp-0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43407462-c704-4740-f2b0-902c28a59a93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "X_train.to(device)\n",
        "y_train.to(device)\n",
        "X_test.to(device)\n",
        "y_test.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QKRiXTGL4wC"
      },
      "source": [
        "## Preparation for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kpdsuy9KLsvl"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.BCELoss() # used for binary classification problems\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDAutLercnnK"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQA9YX0nOpD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6592b601-3c1e-49c0-b897-fc63e58b13ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA: Finished epoch 0, latest loss 0.5796749591827393\n",
            "CUDA: Finished epoch 1, latest loss 0.06000547856092453\n",
            "CUDA: Finished epoch 2, latest loss 0.00020053907064720988\n",
            "CUDA: Finished epoch 3, latest loss 0.004539635498076677\n",
            "CUDA: Finished epoch 4, latest loss 0.06032911315560341\n",
            "CUDA: Finished epoch 5, latest loss 0.00053207523887977\n",
            "CUDA: Finished epoch 6, latest loss 0.00015368965978268534\n",
            "CUDA: Finished epoch 7, latest loss 4.25097496190574e-05\n",
            "CUDA: Finished epoch 8, latest loss 1.1021329555660486e-05\n",
            "CUDA: Finished epoch 9, latest loss 4.478618848224869e-06\n",
            "CUDA: Finished epoch 10, latest loss 2.2729950615030248e-06\n",
            "CUDA: Finished epoch 11, latest loss 1.307728325627977e-06\n",
            "CUDA: Finished epoch 12, latest loss 8.119793051264423e-07\n",
            "CUDA: Finished epoch 13, latest loss 5.306533239490818e-07\n",
            "CUDA: Finished epoch 14, latest loss 3.578057032882498e-07\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 15\n",
        "batch_size = 4\n",
        "\n",
        "# CPU\n",
        "if device == \"cpu\":\n",
        "  for epoch in range(n_epochs):\n",
        "    for i in range(0, len(X) - batch_size, batch_size):\n",
        "      Xbatch = X_train[i:i+batch_size] # specifying the rows\n",
        "      y_pred = model(Xbatch) # scalar\n",
        "      ybatch = y_train[i:i+batch_size]\n",
        "      loss = loss_fn(y_pred, ybatch)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print(f\"epoch: {epoch + 1}/{n_epochs}\", end=\"\\r\")\n",
        "  print(f'CPU: Finished epoch {epoch}, latest loss {loss}')\n",
        "\n",
        "# GPU\n",
        "elif device == \"cuda\":\n",
        "  for epoch in range(n_epochs):\n",
        "    for i in range(0, len(X) - batch_size, batch_size):\n",
        "      Xbatch = X_train[i:i+batch_size] # specifying the rows\n",
        "      y_pred = model(Xbatch.cuda()) # scalar\n",
        "      ybatch = y_train[i:i+batch_size].cuda()\n",
        "      loss = loss_fn(y_pred, ybatch)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print(f\"epoch: {epoch + 1}/{n_epochs}\", end=\"\\r\")\n",
        "    print(f'CUDA: Finished epoch {epoch}, latest loss {loss}')\n",
        "else:\n",
        "  print(\"Not using CPU or CUDA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEcBZ3U9aYrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38527dd7-0b99-44c5-c40b-d5281dd3ea36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Accuracy: 98.54287719726562%\n",
            "Testing Data Accuracy: 94.07766723632812%\n"
          ]
        }
      ],
      "source": [
        "# evaluate the accuracy of the model\n",
        "\n",
        "with torch.no_grad():  # no_grad to avoid differentiating\n",
        "    y_pred1 = model(X_train.to(device))\n",
        "    y_pred2 = model(X_test.to(device))\n",
        "\n",
        "\n",
        "# rounds prediction to nearest integer, check if equal to y\n",
        "accuracy1 = (y_pred1.round() == y_train.to(device)).float().mean()\n",
        "accuracy2 = (y_pred2.round() == y_test.to(device)).float().mean()\n",
        "print(f\"Training Data Accuracy: {accuracy1 * 100}%\")\n",
        "print(f\"Testing Data Accuracy: {accuracy2 * 100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Save model\n"
      ],
      "metadata": {
        "id": "jMn6hrMGDuff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print state dict, a dictionary containing label for each weight/bias and their value\n",
        "for param_tensor in model.state_dict():\n",
        "  print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# print state dict for the optimizer, containing hyperparameters\n",
        "for var_name in optimizer.state_dict():\n",
        "  print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ],
      "metadata": {
        "id": "2V9VToLnDpKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in google drive, this saves inside the folder that the notebook was initially mounted\n",
        "PATH = \"classifier.pt\""
      ],
      "metadata": {
        "id": "K77pg7VJEXre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "Z8F_Woj_EoEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Code for testing**"
      ],
      "metadata": {
        "id": "iz2EPzv5JKGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace variable with local path in linux\n",
        "PATH = \"classifier.pt\""
      ],
      "metadata": {
        "id": "99blsReqJJp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load Existing Model"
      ],
      "metadata": {
        "id": "nYGb80oUE5Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval() # must set dropout and batch normalization layers to evaluation mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY_g84jpE0zW",
        "outputId": "b69c099f-8531-48db-9ce1-41da061430e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=504, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=64, out_features=1, bias=True)\n",
              "    (9): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import rospy\n",
        "# from std_msgs.msg import String\n",
        "\n",
        "# def callback(data):\n",
        "#     rospy.loginfo(rospy.get_caller_id() + 'I heard %s', data.data)\n",
        "\n",
        "# def listener():\n",
        "\n",
        "#     # In ROS, nodes are uniquely named. If two nodes with the same\n",
        "#     # name are launched, the previous one is kicked off. The\n",
        "#     # anonymous=True flag means that rospy will choose a unique\n",
        "#     # name for our 'listener' node so that multiple listeners can\n",
        "#     # run simultaneously.\n",
        "#     rospy.init_node('listener', anonymous=True)\n",
        "\n",
        "#     rospy.Subscriber('/senseglove/0/rh/joint_states', String, callback) # subscribes to this senseglove joints topic\n",
        "\n",
        "#     # spin() simply keeps python from exiting until this node is stopped\n",
        "#     rospy.spin()\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     listener()"
      ],
      "metadata": {
        "id": "qfIuH5oeJVRQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}