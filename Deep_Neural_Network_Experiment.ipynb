{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "f_bwgzHgo3JS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim\n",
        "import numpy as np  # to load dataset\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHabcSsao2TJ",
        "outputId": "897539fc-71e8-43cc-a653-2a8f9110f49d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device in use: cpu\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device in use: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oc3Hvmoc5UR"
      },
      "source": [
        "## For Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo0OejbBc4VB",
        "outputId": "12c6b50b-4a42-4d7b-fec2-d67060a2b1ca"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive/\")\n",
        "# %cd /content/drive/MyDrive/PyTorch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjkBExibcnm-"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "lr1_F96LcnnB"
      },
      "outputs": [],
      "source": [
        "# define the dataset\n",
        "# 0 corresponds to rotating\n",
        "# 1 corresponds to grasping\n",
        "\n",
        "# num rows for one grasp\n",
        "block_size = 2 * 24\n",
        "\n",
        "def normalize_vector(nd_arr: np.ndarray) -> np.ndarray:\n",
        "    vector_length = sum([i ** 2 for i in nd_arr]) ** 0.5\n",
        "    normalized_arr = [i / vector_length for i in nd_arr]\n",
        "    return normalized_arr\n",
        "\n",
        "# Rotation\n",
        "unedited_rotating_dataset = np.loadtxt('rotating.csv', delimiter=\",\")\n",
        "# Split into multiple movements over time (\"block_size\" seconds)\n",
        "edited_rotating_dataset = unedited_rotating_dataset[:,1:21] #corresponding to cols 2 - 21 inclusive, excluding the last row of zeros\n",
        "# Convert positions into velocities\n",
        "edited_rotating_dataset = np.diff(edited_rotating_dataset, axis=0)\n",
        "# Normalize each row\n",
        "edited_rotating_dataset = np.array([normalize_vector(row) for row in edited_rotating_dataset])\n",
        "\n",
        "# Grasping\n",
        "unedited_grasping_dataset = np.loadtxt('grasping.csv', delimiter=\",\")\n",
        "edited_grasping_dataset = unedited_grasping_dataset[:,1:21]\n",
        "edited_grasping_dataset = np.diff(edited_grasping_dataset, axis=0)\n",
        "# Normalize\n",
        "edited_rotating_dataset = np.array([normalize_vector(row) for row in edited_grasping_dataset])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvHUpw2_cnnD"
      },
      "source": [
        "# Process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "yPQUdDtEyXST"
      },
      "outputs": [],
      "source": [
        "columns = edited_rotating_dataset.shape[1]\n",
        "\n",
        "# Rotating\n",
        "rows = edited_rotating_dataset.shape[0]\n",
        "X = np.zeros((rows - block_size + 1, block_size * columns))  # number of rows times columns rows (from flattening)\n",
        "\n",
        "# For each block\n",
        "for i in range(0, rows - block_size + 1):\n",
        "  # Get entire row, 1st block_size * 24 rows, 2nd of them and so on..\n",
        "  X[i] = np.ndarray.flatten(edited_rotating_dataset[i : i + block_size, :])\n",
        "\n",
        "# X now contains mutliple blocks\n",
        "y = np.zeros((rows - block_size + 1))\n",
        "\n",
        "\n",
        "# grasping\n",
        "rows = edited_grasping_dataset.shape[0]\n",
        "X2 = np.zeros((rows - block_size + 1, block_size * columns))\n",
        "# For each block\n",
        "for i in range(0, rows - block_size + 1):\n",
        "  # Get entire row, 1st, block_size * 24 rows, second of them and so on..\n",
        "  X2[i] = np.ndarray.flatten(edited_grasping_dataset[i : i + block_size, :])\n",
        "# X now contains mutliple blocks\n",
        "y2 = np.ones((rows - block_size + 1))\n",
        "combined_X = np.concatenate((X, X2), axis=0)\n",
        "combined_y = np.concatenate((y, y2), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeWk_1YCcnnF"
      },
      "source": [
        "## Prepare for Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "j0SU43jpH6Vt"
      },
      "outputs": [],
      "source": [
        "# Split training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_X, combined_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# covnert into tensors since numpy uses 64 bit floating point\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "y_train = torch.reshape(y_train,(-1,1)) # a single dimension uses -1 to infer the length. new shape\n",
        "y_test = torch.reshape(y_test,(-1,1)) # a single dimension uses -1 to infer the length. new shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "sVsm3hfno_-i"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(block_size * columns, 64), # input\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9v3oCcTp-0q",
        "outputId": "403ee73a-a6b0-4030-e4de-1a8d8453e660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=960, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=16, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
            "    (5): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "X_train.to(device)\n",
        "y_train.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QKRiXTGL4wC"
      },
      "source": [
        "## Preparation for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Kpdsuy9KLsvl"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.BCELoss() # used for binary classification problems\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDAutLercnnK"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQA9YX0nOpD0",
        "outputId": "00358e27-90fa-43d1-9aad-fa1648828b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU: Finished epoch 14, latest loss 3.826694955932908e-05\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 15\n",
        "batch_size = 4\n",
        "\n",
        "# CPU\n",
        "if device == \"cpu\":\n",
        "  for epoch in range(n_epochs):\n",
        "    for i in range(0, len(X) - batch_size, batch_size):\n",
        "      Xbatch = X_train[i:i+batch_size] # specifying the rows\n",
        "      y_pred = model(Xbatch) # scalar\n",
        "      ybatch = y_train[i:i+batch_size]\n",
        "      loss = loss_fn(y_pred, ybatch)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print(f\"epoch: {epoch + 1}/{n_epochs}\", end=\"\\r\")\n",
        "  print(f'CPU: Finished epoch {epoch}, latest loss {loss}')\n",
        "\n",
        "# GPU\n",
        "elif device == \"cuda\":\n",
        "  for epoch in range(n_epochs):\n",
        "    for i in range(0, len(X) - batch_size, batch_size):\n",
        "      Xbatch = X_train[i:i+batch_size] # specifying the rows\n",
        "      y_pred = model(Xbatch.cuda()) # scalar\n",
        "      ybatch = y_train[i:i+batch_size].cuda()\n",
        "      loss = loss_fn(y_pred, ybatch)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print(f\"epoch: {epoch + 1}/{n_epochs}\", end=\"\\r\")\n",
        "  print(f'CUDA: Finished epoch {epoch}, latest loss {loss}')\n",
        "else:\n",
        "  print(\"Not using CPU or CUDA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEcBZ3U9aYrA",
        "outputId": "a3d792ef-0620-4748-a15d-b87641e3c4da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy 0.23079939186573029\n"
          ]
        }
      ],
      "source": [
        "# evaluate the accuracy of the model\n",
        "\n",
        "with torch.no_grad():  # no_grad to avoid differentiating\n",
        "    X_test = X_test.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    y_pred = model(X_test)\n",
        "\n",
        "# rounds prediction to nearest integer, check if equal to y, \n",
        "accuracy = (y_pred.round() == y_test).float().mean()\n",
        "print(f\"Accuracy {accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
